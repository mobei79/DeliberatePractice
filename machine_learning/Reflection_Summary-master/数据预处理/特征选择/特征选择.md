# 为什么要做特征选择？
- 耗时：特征个数越多，分析特征、训练模型所需的时间就越长。
- 过拟合：特征个数越多，容易引起“维度灾难”，模型也会越复杂，其推广能力会下降。    
- 共线性：单因子对目标的作用被稀释，解释力下降

# 从哪些方面可以做特征选择？
- 方差，是的feature内的方向更大，对目标区分度提高更高贡献
- 相关性，与区分目标有高相关的特征才有意义

# 既然说了两个方向，分别介绍一些吧
- 方差
    - 移除低方差特征
        - 移除低方差特征是指移除那些方差低于某个阈值，即特征值变动幅度小于某个范围的特征，这一部分特征的区分度较差，我们进行移除
    - 考虑有值数据中的占比，异常数据的占比，正常范围数据过少的数据也可以移除
- 相关性
    - 单变量特征选择：单变量特征是基于单一变量和目标y之间的关系，通过计算某个能够度量特征重要性的指标，然后选出重要性Top的K个特征。但是这种方式有一个缺点就是忽略了特征组合的情况
        - 皮尔森相关系数:![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8n46pedyoj303e019t8i.jpg)
        - Fisher得分:![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8n4jajze8j31hc0u0dt2.jpg)
        - 假设检验
            - 卡方检验
            - ANOVA
        - 熵检验
            - 互信息熵
                - 度量两个变量之间的相关性,互信息越大表明两个变量相关性越高;互信息为0,两个变量越独立
            - KL散度
            - 相对熵
        